geom_hline(yintercept=beta/(beta+gamma)*lambda,color="blue")+
geom_hline(yintercept=1,color="green")+
xlim(0,100)+
#scale_color_manual(values=c("red", "black","brown"))
labs(y = "R_eff")
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
sample(c(1,3,5,7,9),1)
#install.packages("igraph")
library(igraph)
N <- 10000
delta <- 10
# Poisson network
set.seed(15812)
seq <- rpois(N,delta)
### Checking Realization by Erdos-Gallai Thm
EG_check <- function(DegreeDist){
check_vec <- c(0)
DegreeDist <- sort(DegreeDist,decreasing = T)
N <- length(DegreeDist)
Cum <- cumsum(DegreeDist)
#Mark3: corrected Durfee number m
Dlist <- DegreeDist- c(0:(N-1)) >=0
m <- length(which(Dlist==TRUE))
for (k in c(1:m)) {
RHS <- k*(k-1) + k*(length(DegreeDist[which(which(DegreeDist>=k)>k)]))+sum(DegreeDist[which(DegreeDist<k)])
LHS <- Cum[k]
if (LHS<=RHS) {
check_vec[k] <- 1
} else {
check_vec[k] <- 0
}
}
# m<-min(check_vec)
# return(m)
return(!any(check_vec==0))
}
EG_check(seq)
### A bundle check of both even (fast) and EG(formal)
CheckSeq <- function(Seq){
if((sum(Seq)%%2==0) & (EG_check(Seq))){
return(TRUE)
} else {
return(FALSE)
}
}
CheckSeq(seq)
G <- sample_degseq(  seq
, method = "fast.heur.simple"
)
######### SSA Algorithm for transmission
GilAlgo <- function(  Network
, size
, beta
, gamma
, MaxTime
, InitInfSize=1
, TrackDyn=T
){
Net <- Network
G <- as_adj_list(  Net
, mode = "all"
, loops = "once"
, multiple = TRUE
)
Deg_vec <- degree(Net)
N <- size
g <- gamma
b <- beta
ind <- c(1:N)
# random initial infection with size i_0
i_0 <- InitInfSize
###Radomly chose s vertices to be infected
# InitIndex <- c(sample.int(N,i_0))
# Chose infected node with weight of degree
InitIndex <- sample(c(1:N),i_0,prob=Deg_vec)
#Status: S=0, I=1, R=2
#Initialize status and rate
t <- 0
Status <- rep(0,N)
Status[InitIndex] <- 1
Istep <- length(which(Status==1))
if (TrackDyn==T){
NumStep <- 1
t_vec <- c(t)
S_vec <- c(length(which(Status==0))/N)
I_vec <- c(length(which(Status==1))/N)
R_vec <- c(0)
Infect_time <- rep(NA,N)
Infect_time[InitIndex] <- 0
Infect_num <- rep(0,N)
}
Rate <- rep(0,N)
Rate[InitIndex] <- g
for (i in c(1:i_0)) {
x <- InitIndex[i]
# Network neighbor
Neighbor <- as.vector(G[[x]])
# Susceptible neighbor: update their rate
# Contact <- Neighbor[which(Status[Neighbor]==0)]
Contact <- Neighbor[!Status[Neighbor]]
Rate[Contact] <- b
}
cat("Init Sum", sum(Rate),"\n")
cat("Init index", InitIndex,"\n")
# while loop: keep looping if t<tmax & Istep != 0
# i.e. there is still active infection
while(t<MaxTime & Istep != 0){
## SSA Calculation
Sum <- sum(Rate)
Cum <- cumsum(Rate)
# the vertex index of event:
# cat("Sum is", Sum, ",")
r <- runif(2, min = 0, max = 1)
Event <- min(which(Cum>r[1]*Sum))
# Infection: status 0 to 1
# Recovery: status 1 to 2
Status[Event] <- Status[Event]+1
# Network neighbor of event index
Neighbor <- as.vector(G[[Event]])
# Susceptible neighbor: update their rate
Contact <- Neighbor[!Status[Neighbor]]
# cat("contact: ", Contact,"\n")
# Infected neighbor: Potential infectors
Infector <- Neighbor[which(Status[Neighbor]==1)]
## Time spent for event happen
Tstep <- -log(r[2])/Sum
t <- t+Tstep
# cat("Event index is", Event,",")
# cat("Status is", Status[Event],"\n")
# if (Sum<0){
#   return(Rate)
#   break
# }
## Update status
if (Status[Event]==2){               ## Recovery
Rate[Event] <- 0
Rate[Contact] <- Rate[Contact]-b
} else if (Status[Event]==1){        ## Infection
Rate[Event] <- g
Rate[Contact] <- Rate[Contact]+b   ## Independence: linear
if (TrackDyn==T){
# vector of infection time of vertices
# NA if not being infected eventually
Infect_time[Event] <- t
# For each infection event in SSA, we might not be able
# to figure out the exactly one infector as the event is
# determined by the rate of infectee i.e. number of its
# actively infected neighbor.
# But since exponential distribution of infection time
# have the Memorylessness property, and we are assuming all
# neighbor are iid and considering an expectation, we can average
# out the new infection event to all active infected neighbor
# at the moment of event.
# Infect_num[Infector] <- Infect_num[Infector]+1/(length(Infector))
# As suggested by Ben, we now randomly chose one infector (if more than
# one) instead of do the average
samp_inf <- sample(Infector,1)
Infect_num[samp_inf] <- Infect_num[samp_inf]+1
}
} else {
}
## Active number of infections of the whole network
Istep <- length(which(Status==1))
## Update proportion
if (TrackDyn==T){
NumStep <- NumStep+1
t_vec[NumStep] <- t
S_vec[NumStep] <- length(which(Status==0))/N
I_vec[NumStep] <- length(which(Status==1))/N
R_vec[NumStep] <- length(which(Status==2))/N
}
}
## Final sizes
FinishTime <- t
Ssize <- length(which(Status==0))/N
Isize <- length(which(Status==1))/N
Rsize <- length(which(Status==2))/N
FinalStat <- data.frame(FinishTime,Ssize,Isize,Rsize)
if (TrackDyn==T){
Track <- cbind(t_vec,S_vec,I_vec,R_vec)
Infect <- cbind(ind,Infect_time,Infect_num)
return(list(FinalStat=FinalStat,Details=Track,Reff=Infect))
} else {
return(FinalStat)
}
}
beta <- 0.25
gamma <- 0.2
result <- GilAlgo(G, N, beta, gamma, MaxTime = 150)
#
result$FinalStat
result <- GilAlgo(G, N, beta, gamma, MaxTime = 150)
#
result$FinalStat
result <- GilAlgo(G, N, beta, gamma, MaxTime = 150)
#
result$FinalStat
result <- GilAlgo(G, N, beta, gamma, MaxTime = 150)
#
result$FinalStat
result <- GilAlgo(G, N, beta, gamma, MaxTime = 150)
#
result$FinalStat
result <- GilAlgo(G, N, beta, gamma, MaxTime = 150)
#
result$FinalStat
result$Details
result$Reff
result$Details
#
result$FinalStat
result$Details
## rm(list=ls())
## wd <- getwd()
# install.packages("zoo")
### Package Part
library(pracma)
library(zoo)
library(gsl)
library(deSolve)
library(igraph)
library(ggplot2)
library(cbinom)
source("NetworkSimulator.R")
setwd("D:/GitHub/STAT794_BigData_RZ")
library(DBI)
con <- dbConnect(          # use in other settings
RPostgres::Postgres(),
# without the previous and next lines, some functions fail with bigint data
#   so change int64 to integer
bigint = "integer",
host = "localhost",
port = 5432,  # this version still using 5432!!!
user = "postgres",
password = "postgres",
dbname = "Adventureworks"
)
print(con)
library(DBI)
con <- dbConnect(          # use in other settings
RPostgres::Postgres(),
# without the previous and next lines, some functions fail with bigint data
#   so change int64 to integer
bigint = "integer",
host = "localhost",
port = 5432,  # this version still using 5432!!!
user = "postgres",
password = "postgres",
dbname = "Adventureworks"
)
install.packages("RPostgres")
library(DBI)
library(RPostgres)
con <- dbConnect(          # use in other settings
RPostgres::Postgres(),
# without the previous and next lines, some functions fail with bigint data
#   so change int64 to integer
bigint = "integer",
host = "localhost",
port = 5432,  # this version still using 5432!!!
user = "postgres",
password = "postgres",
dbname = "Adventureworks"
)
print(con)
dbExecute(con, "set search_path to sales;")
dbListTables(con)
print(con)
dbExecute(con, "set search_path to sales;")
print(con)
dbExecute(con, "set search_path to sales;")
dbListTables(con)
library(sqlpetr)
install.packages("sqlpetr")
library(sqlpetr)
# library(bookdown)
library(here)
install.packages("here")
library(tidyverse)
library(DBI)
library(RPostgres)
library(glue)
#require(knitr)
library(dbplyr)
library(sqlpetr)
remotes::install_github("smithjd/sqlpetr", force = TRUE, build = FALSE, quiet = TRUE)
library(tidyverse)
library(DBI)
library(RPostgres)
library(glue)
#require(knitr)
library(dbplyr)
library(sqlpetr)
# library(bookdown)
library(here)
con <- dbConnect(          # use in other settings
RPostgres::Postgres(),
# without the previous and next lines, some functions fail with bigint data
#   so change int64 to integer
bigint = "integer",
host = "localhost",
port = 5432,  # this version still using 5432!!!
user = "postgres",
password = "postgres",
dbname = "Adventureworks"
)
print(con)
dbExecute(con, "set search_path to sales;")
dbListTables(con)
dbListFields(con, "salesorderheader")
tbl(con, in_schema("sales", "salesorderheader")) %>%
head()
sqlpetr::sp_docker_start("adventureworks")
Sys.sleep(sleep_default)
dbExecute(con, "set search_path to sales, humanresources;")
salesorderheader_tibble <- DBI::dbReadTable(con, "salesorderheader")
str(salesorderheader_tibble)
salesorderheader_tibble <- salesorderheader_tibble[,1:13]
### 7.2.2
salesorderheader_table <- dplyr::tbl(con, "salesorderheader")
class(salesorderheader_table)
### 7.2.3
salesorderheader_table %>% dplyr::collect(n = 3) %>% dim()
salesorderheader_table %>% dplyr::collect(n = 500) %>% dim()
### 7.2.4
one_percent_sample <- DBI::dbGetQuery(
con,
"SELECT orderdate, subtotal, taxamt, freight, totaldue
FROM salesorderheader TABLESAMPLE BERNOULLI(3) LIMIT 20;
"
)
one_percent_sample
DBI::dbListFields(con, "salesorderheader")
print(one_percent_sample)f
print(one_percent_sample)
DBI::dbListFields(con, "salesorderheader")
salesorderheader_df <- DBI::dbReadTable(con, "salesorderheader")
(max_id <- max(salesorderheader_df$salesorderid))
(min_id <- min(salesorderheader_df$salesorderid))
sample_rows <- sample(min_id:max_id, 10)
salesorderheader_table <- dplyr::tbl(con, "salesorderheader")
salesorderheader_sample <- salesorderheader_table %>%
dplyr::filter(salesorderid %in% sample_rows) %>%
dplyr::collect()
str(salesorderheader_sample)
### 7.2.5
salesorderheader_table %>% dplyr::select(orderdate, subtotal, taxamt, freight, totaldue) %>%
head()
DBI::dbGetQuery(
con,
'SELECT "orderdate", "subtotal", "taxamt", "freight", "totaldue"
FROM "salesorderheader"
LIMIT 6')
tbl(con, "salesorderheader") %>%
dplyr::rename(order_date = orderdate, sub_total_amount = subtotal,
tax_amount = taxamt, freight_amount = freight, total_due_amount = totaldue) %>%
dplyr::select(order_date, sub_total_amount, tax_amount, freight_amount, total_due_amount ) %>%
show_query()
### 7.3
salesorderheader_table %>%
dplyr::tally() %>%
dplyr::show_query()
DBI::dbGetQuery(
con,
'SELECT COUNT(*) AS "n"
FROM "salesorderheader"   '
)
### 7.3
salesorderheader_table %>%
dplyr::tally() %>%
dplyr::show_query()
salesorderheader_table %>% dim()
### 7.3
salesorderheader_table %>%
dplyr::tally() %>%
dplyr::show_query()
Sys.Date()
DBI::dbGetQuery(
con,
'SELECT COUNT(*) AS "n"
FROM "salesorderheader"   '
)
query_results
dbDisconnect(con)
zsh?
# shift+Enter gives > in a new line of CL input
# where is the ~/.zshrc configuration file for zsh?
# shift+Enter gives > in a new line of CL input
###### Ch3
Runing the image
## Runing the image
# docker run --rm -it -v ${PWD}:/home/dst/data datasciencetoolbox/dsatcl2e
###### Ch2
#
library(tidyverse)
library(DBI)
library(RPostgres)
library(connections)
library(glue)
require(knitr)
library(dbplyr)
library(sqlpetr)
library(bookdown)
#library(bookdown)
library(lubridate)
library(gt)
# con <- connection_open(  # use in an interactive session
con <- dbConnect(          # use in other settings
RPostgres::Postgres(),
# without the previous and next lines, some functions fail with bigint data
#   so change int64 to integer
bigint = "integer",
host = "localhost",
port = 5432,
user = "postgres",
password = "postgres",
dbname = "adventureworks"
)
dbExecute(con, "set search_path to sales;") # so that `dbListFields()` works
dbListTables(con)
dbListFields(con, "salesorderheader")
dbListFields(con, "sales")
dbListFields(con)
orderheader
dbListFields(con, "salesorderheader")
dbListTables(con)
dbListTables(con)
# con <- connection_open(  # use in an interactive session
con <- dbConnect(          # use in other settings
RPostgres::Postgres(),
# without the previous and next lines, some functions fail with bigint data
#   so change int64 to integer
bigint = "integer",
host = "localhost",
port = 5432,
user = "postgres",
password = "postgres",
dbname = "adventureworks"
)
dbExecute(con, "set search_path to sales;") # so that `dbListFields()` works
dbListTables(con)
dbDisconnect(con)
# con <- connection_open(  # use in an interactive session
con <- dbConnect(          # use in other settings
RPostgres::Postgres(),
# without the previous and next lines, some functions fail with bigint data
#   so change int64 to integer
bigint = "integer",
host = "localhost",
port = 5432,
user = "postgres",
password = "postgres",
dbname = "Adventureworks"
)
dbExecute(con, "set search_path to sales;") # so that `dbListFields()` works
dbListTables(con)
dbListFields(con, "vsalespersonsalesbyfiscalyearsdata")
### 11.3.1
v_salesperson_sales_by_fiscal_years_data <-
tbl(con, in_schema("sales","vsalespersonsalesbyfiscalyearsdata")) %>%
collect()
str(v_salesperson_sales_by_fiscal_years_data)
tbl(con, in_schema("sales","vsalespersonsalesbyfiscalyearsdata")) %>%
count(salesterritory, fiscalyear) %>%
collect() %>% # ---- pull data here ---- #
pivot_wider(names_from = fiscalyear, values_from = n, names_prefix = "FY_")
tbl(con, in_schema("sales","vsalespersonsalesbyfiscalyearsdata")) %>%
count(salesterritory, fiscalyear) %>%
collect()
tbl(con, in_schema("sales","vsalespersonsalesbyfiscalyearsdata")) %>%
count(salesterritory, fiscalyear) %>%
collect() %>% # ---- pull data here ---- #
pivot_wider(names_from = fiscalyear, values_from = n, names_prefix = "FY_")
### 11.3.2
view_definition <- dbGetQuery(con, "select
pg_get_viewdef('sales.vsalespersonsalesbyfiscalyearsdata',
true)")
cat(unlist(view_definition$pg_get_viewdef))
soh <-
tbl(con, in_schema("sales","salesorderheader")) %>%
collect()
soh
soh <- dbGetQuery(con, "SELECT soh.orderdate
FROM salesorderheader soh")
soh
soh <- dbGetQuery(con, "SELECT soh.orderdate + '6 mons'::interval
FROM salesorderheader soh")
soh
soh[1:3]
soh[1:3,]
soh <- dbGetQuery(con, "SELECT soh.orderdate
FROM salesorderheader soh")
soh[1:3,]
dbDisconnect(con)
docker rm --force adventrueworks
